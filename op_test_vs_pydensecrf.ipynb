{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import filter_ops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import datetime\n",
    "def ts(fmt='%d-%m-%y-%H:%M:%S'):\n",
    "    return datetime.datetime.now().strftime(fmt)\n",
    "\n",
    "def tf_config(devices='0'):\n",
    "      return tf.ConfigProto(allow_soft_placement=False,\n",
    "                            gpu_options=tf.GPUOptions(allow_growth=True,\n",
    "                                                      visible_device_list=devices))\n",
    "def relative_error(x, y, norm=np.abs, eps=1e-6):\n",
    "    return norm(x - y) / (np.maximum(norm(x), norm(y)) + eps)\n",
    "\n",
    "# initialization\n",
    "outputs = {}\n",
    "N, C, F = 64*64, 8, 3\n",
    "unaries_shape = [N, C]\n",
    "features_shape = [N, F]\n",
    "\n",
    "np.random.seed(123)\n",
    "np_compat = np.random.normal(0.0, 1.0, size=(C, C)).astype(np.float32)\n",
    "np_compat = np_compat.dot(np_compat.T)\n",
    "np_unaries = np.random.normal(size=unaries_shape).astype(np.float32)\n",
    "np_features = np.random.normal(0.0, 10.0, size=features_shape).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## our tf/cpp implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(logits, axis=None):\n",
    "    l_exp = tf.exp(logits - tf.reduce_max(logits, axis=axis, keep_dims=True))\n",
    "    return l_exp / tf.reduce_sum(l_exp, axis=axis, keep_dims=True)\n",
    "\n",
    "def meanfield_iteration(q, unaries, lattice, compat):\n",
    "    \"\"\"a single iteration of MF inference\n",
    "    Args:\n",
    "        q - [N, C] current probabilities\n",
    "        unaries - [N, C]\n",
    "        lattice - result of `filter_ops.init_lattice`\n",
    "        compat - [C, C] symmetric (!) matrix\n",
    "    Returns:\n",
    "        probabilities at next step\n",
    "    \"\"\"\n",
    "    pairwise = - filter_ops.ph_filter(q, lattice)\n",
    "    if len(compat.shape) == 2:\n",
    "        pairwise = tf.matmul(pairwise, compat)\n",
    "    else:\n",
    "        pairwise = pairwise * compat\n",
    "    q_nat = - (unaries + pairwise)\n",
    "    return softmax(q_nat, axis=-1)\n",
    "\n",
    "def meanfield_op(unaries, lattice, compat, num_iters):\n",
    "    q_init = softmax(-unaries, axis=-1)    \n",
    "    \n",
    "    def _iter(prev, it):\n",
    "        return meanfield_iteration(prev, unaries, l)\n",
    "    \n",
    "    q = tf.foldl(lambda prev, it: meanfield_iteration(prev, unaries, \n",
    "                 tf.range(0, num_iters), \n",
    "                 initializer=q_init,\n",
    "                 parallel_iterations=32)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-64cc00f0b4a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlattice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermuto_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeanfield_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlattice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlattice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0b78f13ea038>\u001b[0m in \u001b[0;36mmeanfield_op\u001b[0;34m(unaries, lattice, compat, num_iters)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmeanfield_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlattice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mq_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0munaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     q = tf.foldl(_iter, \n\u001b[0m\u001b[1;32m     26\u001b[0m                  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                  \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_iter' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_iters = 10\n",
    "\n",
    "# negative log-probability\n",
    "unaries = tf.convert_to_tensor(np_unaries)\n",
    "features = tf.convert_to_tensor(np_features)\n",
    "compat = tf.convert_to_tensor(np_compat)\n",
    "lattice = filter_ops.permuto_init(np_features)\n",
    "\n",
    "q = meanfield_op(unaries, lattice, compat, num_iters)\n",
    "tf_out = filter_ops.ph_filter(inputs, lattice)\n",
    "\n",
    "with tf.Session(config=tf_config()) as sess:\n",
    "    print(f'[{ts()}] running')\n",
    "    _q_tf = sess.run(q)\n",
    "    _lattice, _tf_out = sess.run([lattice, tf_out])\n",
    "    print(f'[{ts()}] done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing how close the results are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydensecrf.densecrf as dcrf\n",
    "\n",
    "crf = dcrf.DenseCRF(N, C)\n",
    "crf.setUnaryEnergy(np_unaries.T.copy())\n",
    "\n",
    "if isinstance(np_compat, float):\n",
    "    crf.addPairwiseEnergy(np_features.T.copy(), \n",
    "                          np_compat,\n",
    "                          dcrf.CONST_KERNEL,\n",
    "                          dcrf.NO_NORMALIZATION)\n",
    "else:\n",
    "    crf.addPairwiseEnergy(np_features.T.copy(), \n",
    "                          -np_compat,\n",
    "                          dcrf.CONST_KERNEL,\n",
    "                          dcrf.NO_NORMALIZATION)\n",
    "    \n",
    "\n",
    "print(f'[{ts()}] running')\n",
    "\n",
    "q, tmp1, tmp2 = crf.startInference()\n",
    "_q_init_py = np.array(q).T\n",
    "for i in range(num_iters):\n",
    "    crf.stepInference(q, tmp1, tmp2)\n",
    "_q_py = np.array(q).T\n",
    "\n",
    "print(f'[{ts()}] done!')\n",
    "\n",
    "print('difference in q:', np.abs(_q_py - _q_tf).max())\n",
    "\n",
    "print(np.unique(np.argmax(_q_py, axis=1), return_counts=True))\n",
    "print(np.unique(np.argmax(_q_tf, axis=1), return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference numpy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's try numpy implementation\n",
    "def np_softmax(logits, axis=None):\n",
    "    l_max = np.max(logits, axis=axis, keepdims=True)\n",
    "    l_exp = np.exp(logits - l_max)\n",
    "    return l_exp / np.sum(l_exp, axis=axis, keepdims=True)\n",
    "\n",
    "def np_splat(inputs, offsets, weights, nbs):\n",
    "    N, C = inputs.shape\n",
    "    F = weights.shape[1] - 1\n",
    "    M = nbs.shape[0]\n",
    "    # splatting\n",
    "    ## compute inputs multiplied by the weights\n",
    "    weighted_inputs = np.matmul(weights[:N,:,np.newaxis], \n",
    "                                inputs[:N,np.newaxis,:])\n",
    "    weighted_inputs = weighted_inputs.reshape([-1, C])\n",
    "    ## sum up at corresponding indices (update with duplicatess)\n",
    "    idxs = offsets[:N,:F+1].reshape((-1,))+1\n",
    "    values = np.zeros([M+2, C])\n",
    "    # TODO: this is the only op that is hard to do with grads\n",
    "    np.add.at(values, idxs, weighted_inputs)\n",
    "    return values\n",
    "\n",
    "def np_blur(inputs, values_in, offsets, weights, nbs):\n",
    "    F = weights.shape[1] - 1\n",
    "    values = values_in.copy()\n",
    "    # NOTE: we actually ignore the last update?\n",
    "    for j in range(F+1):\n",
    "        n1 = values[nbs[:,j,0]+1]\n",
    "        n2 = values[nbs[:,j,1]+1]\n",
    "        values[1:-1] += 0.5 * (n1 + n2)\n",
    "    return values\n",
    "\n",
    "def np_slice(inputs, values, offsets, weights, nbs):\n",
    "    N, C = inputs.shape\n",
    "    F = weights.shape[1] - 1\n",
    "    M = nbs.shape[0]\n",
    "    alpha = 1.0 / (1.0 + 2.0**(-F))\n",
    "    idxs = offsets[:N,:F+1].reshape((-1,))+1\n",
    "    w = weights[:N,:,np.newaxis]\n",
    "    v = values[idxs].reshape((N, F+1, C))\n",
    "    return np.sum(alpha * w * v, axis=1)\n",
    "\n",
    "def np_filter(inputs, offsets, weights, nbs):\n",
    "    v_splat = np_splat(inputs, offsets, weights, nbs)\n",
    "    v_blur = np_blur(inputs, v_splat, offsets, weights, nbs)\n",
    "    return np_slice(inputs, v_blur, offsets, weights, nbs)\n",
    "    \n",
    "offsets = _lattice.offsets\n",
    "weights = _lattice.weights\n",
    "nbs = _lattice.neighbours\n",
    "inputs = np_softmax(-np_unaries, axis=1)\n",
    "\n",
    "np_out = np_filter(inputs, *_lattice)\n",
    "err = np.max(np.abs(np_out - _tf_out))\n",
    "print(f'max error tf vs numpy: {err}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
